<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head;
         any other head content must come *after* these tags -->

    <!-- Icon to use on the browser bar -->
    <link rel="icon" href="calendar/images/web-icon.png">

    <!-- Bootstrap core CSS -->
    <link href="calendar/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Skeleton CSS -->
    <link rel="stylesheet" href="calendar/Skeleton/css/normalize.css">
    <link rel="stylesheet" href="calendar/Skeleton/css/skeleton.css">
    <link rel="stylesheet" href="calendar/css/skeleton-modifications.css">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="calendar/bootstrap3-ie10-viewport-bug-workaround/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Fonts -->
    <link href='calendar/fonts/raleway.css' rel='stylesheet' type='text/css'>

    <!-- Ace Code Editor - https://ace.c9.io/ -->
    <script type="text/javascript" src="calendar/ace-builds/src-noconflict/ace.js" charset="utf-8">
    </script>

    <!-- Chart.js - http://www.chartjs.org -->
    <script type="text/javascript" src="calendar/chartjs/Chart.bundle.min.js" charset="utf-8">
    </script>

    <!-- To support challenge/response authentication within course notes-->
        <script type="text/javascript">
      var nonce = "67e8daa8e20f7ff65393a3baddd861251ff51e2c0c3ba86c9b4394f35deb4a17";
    </script>
    <script type="text/javascript" src="calendar/js/sha256.js"></script>
    
    <!-- Styles for the submission System -->
    <link href="calendar/css/calendar-default.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ["\\(","\\)"] ],
          processEscapes: true
        }
      });
    </script>
    <script type="text/javascript" src="../../ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <!-- Highlight.js -->
    <link rel="stylesheet" href="calendar/highlight/styles/color-brewer.css">
    <script src='calendar/highlight/highlight.pack.js'></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- Font-Awesome -->
    <link rel="stylesheet" type="text/css" href="calendar/Font-Awesome/css/font-awesome.min.css">

    <!-- Datatables -->
    <link rel="stylesheet" type="text/css" href="calendar/datatables.net/datatables.min.css">

    <!-- Printing -->
    <link rel="stylesheet" type="text/css" media="print" href="calendar/css/calendar-print.css">

    <!-- Custom CSS based on user preferences -->
    <link href='docs/sy110_cdrD.css' rel='stylesheet'>
      
      
    <!-- Custom JavaScript based on user preferences -->

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="calendar/jquery/js/jquery-3.3.1.min.js"></script>
    <script src="calendar/bootstrap/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="calendar/bootstrap3-ie10-viewport-bug-workaround/ie10-viewport-bug-workaround.js"></script>
    <!-- DataTables -->
    <script type="text/javascript" src="calendar/datatables.net/datatables.min.js"></script>

  <title>SY110 (Fall 2020)</title>

  </head>
  <body>

    <!-- Fixed navbar -->
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!--
            <a class="navbar-brand" href="#">
              <img alt="Navbar!" src="css/images/web-icon.png" width="24">
            </a>
          -->
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">

            <li><a href="calendar.php.html?load=home">
                SY110 - Introduction to Cyber Security</a></li>

            
            <li><a title="Calendar" href="calendar.php-1.html?show=calendar_display">
                <span class="glyphicon glyphicon-calendar" aria-hidden="true"></span>
                </a></li>

            <li><a title="Resources" href="calendar.php-2.html?load=resources">
                <span class="glyphicon glyphicon-briefcase" aria-hidden="true"></span>
                </a></li>

            <li><a title="Information" href="calendar.php-3.html?load=policy">
                <span class="glyphicon glyphicon-info-sign" aria-hidden="true"></span>
                </a></li>

        
        
          </ul>

        
          <ul class="nav navbar-nav navbar-right">
            <li class="dropdown">
<a href="#" title="View files associated with lecture" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
Cyberspace as a Human Domain
</a>
<ul class="dropdown-menu  scrollable-menu">
<li class="dropdown-header">Options</li>
<li><form method="post" class="navbar-form navbar-left" role="search" target="_blank">
  <div class="input-group">
    <input type="hidden" class="form-control" name="print" id="print">
    <div class="input-group-btn">
        <button class="btn btn-default" type="submit"><i class="glyphicon glyphicon-print"></i> Print</button>
    </div>
  </div>
</form></li>
<li><form method="get" class="navbar-form navbar-left" role="search">
  <div class="input-group">
    <input type="hidden" name="show" value="calendar_search">
    <input type="text" class="form-control" placeholder="Search" name="search" id="search">
    <div class="input-group-btn">
        <button class="btn btn-default" type="submit"><i class="glyphicon glyphicon-search"></i></button>
    </div>
  </div>
</form></li>
<li><form method="post" class="navbar-form navbar-left" role="search" onsubmit="return hashPassword()">
  <div class="input-group">
    <input type="password" class="form-control" placeholder="Password" name="password" id="password">
    <div class="input-group-btn">
        <button class="btn btn-default" type="submit"><i class="glyphicon glyphicon-lock"></i></button>
    </div>
</div>
</form></li>
</ul>
</li>
            <li class="dropdown">
              <a href="#" title="Select class" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                <span class="glyphicon glyphicon-apple" aria-hidden="true"></span>
                Class<span class="caret"></span></a>
              <ul class="dropdown-menu  scrollable-menu">
                <li><a href='calendar.php-4.html?type=class&event=1'>1 - Intro to the Cyber Domain</a></li>
<li><a href='calendar.php-5.html?type=class&event=2'>2 - Aspects and Pillars of Cyber Security</a></li>
<li><a href='calendar.php-6.html?type=class&event=3'>3 - Computer Architecture</a></li>
<li><a href='calendar.php-7.html?type=class&event=4'>4 - Risk And Vulnerabilities</a></li>
<li><a href='calendar.php-8.html?type=class&event=5'>5 - Policy And Law</a></li>
<li><a href='calendar.php-9.html?type=class&event=6'>6 - Bits And Bytes And Files</a></li>
<li><a href='calendar.php-10.html?type=class&event=7'>7 - OS-File Systems</a></li>
<li><a href='calendar.php-11.html?type=class&event=8'>8 - OS-Permissions, Shell, And Remote Access</a></li>
<li><a href='calendar.php-12.html?type=class&event=9'>9 - Web And HTML</a></li>
<li><a href='calendar.php-13.html?type=class&event=10'>10 - JavaScript - Overview</a></li>
<li><a href='calendar.php-14.html?type=class&event=11'>11 - Vulnerabilities and Malware</a></li>
<li><a href='calendar.php-15.html?type=class&event=12'><font color='black'><b>12 - Cyberspace as a Human Domain</b></font></a></li>
<li><a href='calendar.php-16.html?type=class&event=13'>13 - Client-Side Scripting: Part One</a></li>
<li><a href='calendar.php-17.html?type=class&event=14'>14 - Client-Side Scripting: Part Two</a></li>
<li><a href='calendar.php-18.html?type=class&event=15'>15 - Server-Side Scripting</a></li>
<li><a href='calendar.php-19.html?type=class&event=16'>16 - Human Factors in Cyber Operations</a></li>
<li><a href='calendar.php-20.html?type=class&event=17'>17 - Stack-Intro and Physical Layer</a></li>
<li><a href='calendar.php-21.html?type=class&event=18'>18 - Stack - Data Link Layer</a></li>
<li><a href='calendar.php-22.html?type=class&event=19'>19 - Stack - Network Layer</a></li>
<li><a href='calendar.php-23.html?type=class&event=20'>20 - Stack - Transport Layer</a></li>
<li><a href='calendar.php-24.html?type=class&event=21'>21 - Stack - Application Layer</a></li>
<li><a href='calendar.php-25.html?type=class&event=22'>22 - Wireless</a></li>
<li><a href='calendar.php-26.html?type=class&event=23'>23 - Network Security Appliances and Firewalls</a></li>
<li><a href='calendar.php-27.html?type=class&event=24'>24 - Symmetric Encryption</a></li>
<li><a href='calendar.php-28.html?type=class&event=25'>25 - Asymmetric Encryption</a></li>
<li><a href='calendar.php-29.html?type=class&event=26'>26 - Steganography</a></li>
<li><a href='calendar.php-30.html?type=class&event=27'>27 - Digital Forensics</a></li>
<li><a href='calendar.php-31.html?type=class&event=28'>28 - Cyber Recon</a></li>
<li><a href='calendar.php-32.html?type=class&event=29'>29 - Attackers And Defenders</a></li>
<li><a href='calendar.php-33.html?type=class&event=30'>30 - Cyber Attack</a></li>
<li><a href='calendar.php-34.html?type=class&event=31'>31 - Cyber Defense</a></li>
              </ul>
            </li>
                        <li class="dropdown">
              <a href="#" title="Select lab" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                <span class="glyphicon glyphicon-knight" aria-hidden="true"></span>
                Lab<span class="caret"></span></a>
              <ul class="dropdown-menu  scrollable-menu">
                <li><a href='calendar.php-35.html?type=lab&event=1'>1 - Computer Architecture And Supply Chain</a></li>
<li><a href='calendar.php-36.html?type=lab&event=2'>2 - Windows-Unix Shell And Command Line</a></li>
<li><a href='calendar.php-37.html?type=lab&event=3'>3 - Introduction to Build a Website</a></li>
<li><a href='calendar.php-38.html?type=lab&event=4'>4 - Injection Attacks and XSS</a></li>
<li><a href='calendar.php-39.html?type=lab&event=5'>5 - LAN-WLAN</a></li>
<li><a href='calendar.php-40.html?type=lab&event=6'>6 - Hashing And Passwords</a></li>
<li><a href='calendar.php-41.html?type=lab&event=7'>7 - Digital Certificates</a></li>
<li><a href='calendar.php-42.html?type=lab&event=8'>8 - Digital Forensics</a></li>
<li><a href='calendar.php-43.html?type=lab&event=9'>9 - Cyber Recon</a></li>
<li><a href='calendar.php-44.html?type=lab&event=10'>10 - Cyber Attack</a></li>
<li><a href='calendar.php-45.html?type=lab&event=11'>11 - Cyber Defense</a></li>
<li><a title='Material not online at this time' href='#'><span style='color=#AAAAAA'>12 - _archive</span></a></li>
              </ul>
            </li>
            
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

  <!-- End TopBar and CSS Stuff! -->
<!-- Begin providing the contents of the page -->
<div class="container">
﻿<!DOCTYPE html>
<html>
<head>

<style>

figure {
  float: right;
  border-top: none;
  padding-top: 10px;
  margin-block-start: 10px;
  margin-block-end: 10px;
  margin-inline-start: 10px;
  margin-inline-end: 10px;
}
img {
  display: block;
  margin-left: auto;
  margin-right: auto;

}
figcaption {
  border-bottom: none;
  text-align:center;
}

.center {
    display: block;
    margin-left: auto;
    margin-right: auto;
  border
}

</style>

</head>
<body>
<title>– Cyberspace as a Human Domain</title>
<!-- Begin providing the contents of the page -->
<div class="container">
  
  
    <span id="top"></span>
    <div class="noScreen">
      <br><br><br><h1>Cyberspace as a Human Domain</h1>
    </div>
  
    <div class="learnObjs">
      <h2>Learning Outcomes</h2>
      <p>
        After reviewing this material you should be able to:
      </p>
      <ul>
    <li>Describe the cyber domain as an inescapably human domain.</li>
    <li>Understand and describe key historical stages in the early development of cyberspace.</li>
    <li>Understand and describe the difference between white hat, grey hat, and black hat hacking.</li>
    <li>Understand how human behavior is constrained by ethical issues that arise in cyberspace.</li>
      </ul>
    </div>
    
  <br>
    <br>
    
  <div id="discussion">
  
  
      <h2>Discussion <!--SPAN class="samePageLink">[<A href="#top">Top</A>]</SPAN--></h2>

    <p>From the early 1960s through the 1990s, the realization gradually spread that computer networks were vulnerable to information breaches, whether through spillage or offensive cyber operations.  Sometimes this realization came from scientists deep within the national security infrastructure, such as National Security Agency (NSA) scientist Bernard Peters, who, in 1967, warned that security cannot be guaranteed in any “Multi-Programmed” computer system with remote terminal access (Peters 1967).  At other times this realization came from quite unexpected directions.  For example, the 1983 Hollywood thriller WarGames, in which a technically proficient high-schooler nearly causes a US-Soviet nuclear exchange by hacking into a top secret Pentagon computer, had so impressed President Ronald Reagan, a former actor who loved films and received a private screening of the movie in the White House, that he asked top security advisors whether US military networks were vulnerable to such intrusion.  His question had surprised them.  Their answer—“unfortunately yes”—which came a week later, surprised Reagan even more and in 1984 led to the first US National Security Decision Directive (<a href="../../id/6879742.html">NSDD-145</a>) making the National Security Agency responsible for protecting government telecommunications systems (Warner 2012).</p>
    
    <figure style="float:right"><img src="wargames.JPG?key=f5de89e18c67dc687a4deb78e7517e5c8134cd35&type=class&event=12" alt="wargames"><figcaption>1983 thriller WarGames</figcaption></figure>
    
    <p>Unfortunately, throughout this history cyber operations had been too often understood as a purely technical activity—clever hackers attacking networks defended by equally smart technical defenders.  Within this framework it seemed that technical superiority, such as faster processing, stronger encryption, or more advanced protocols, ultimately determined the security of networks.  This point of view still captures the imagination of the general public.  Yet this picture is completely wrong for it overlooks the human element.  Almost every prominent contemporary cyber operation has targeted human vulnerabilities as its central exploit, whether it is exploiting an individual’s trust (<a href="../../2016/05/13/business/dealbook/swift-global-bank-network-attack.html">2015 SWIFT banking hack</a>), the ability to trick people through impersonation (<a href="../../2016/10/inside-cyberattack-shocked-us-government/index.htm">2015 Office of Personnel Management</a>), the human proclivity to fall for phishing scams (<a href="../../files/documents/ICA_2017_01.pdf">2016 DNC Hack</a>), an inability or unwillingness to patch software (<a href="../../blogs/threat-intelligence/petya-ransomware-wiper.html">2017 Petya</a>, <a href="../../blogs/threat-intelligence/wannacry-ransomware-attack.html">2017 WannaCry</a>) or the human choice to use outdated cryptographic tools (<a href="../../story/under-armour-myfitnesspal-hack-password-hashing/index.htm">2018 Under Armour</a>). </p>
    
    <p>That human beings comprise the most potent attack-vector comes as no surprise to cybersecurity researchers, who have come to see humans as the “weakest link” in any computer network (Greiner 2008).  This lesson traces the <b>history of human-computer interaction</b> from the earliest days of the Computer Age and highlights <b>ethical challenges</b> that emerged alongside the growth of this technology.</p>

  </div>
  
  <div id="early_beginnings">
  <h2>Early Beginnings</h2>
  <p>In 1821, the Cambridge mathematician Charles Babbage (1791-1871) lamented the fact that the only way to check to see if an arithmetical result was correct was to either consult a pre-calculated reference table, which were often full of errors, or to have several human beings (called “computers” at that time) do the computation by hand and compare their results.  Referencing the greatest invention of his day, the steam engine, a frustrated Babbage exclaimed, “I wish the sum could be calculated by steam!”  He began his quest to design a calculating machine that would do arithmetic utilizing purely mechanical properties.  The result was his “Difference Engine,” a decimal-based mechanical calculator that reliably computed basic arithmetical functions simply by setting up initial conditions and turning a hand crank.  Eventually, Babbage’s research led him, in 1837, to conceive of the “Analytical Engine,” a greatly improved design that was never fully built within Babbage’s lifetime but was documented meticulously in his notebooks.  The <b>Analytical Engine</b> was much more complex than the Difference Engine and utilized a punch-card system to run Babbage’s arithmetic tasks.  Ada Lovelace, a mathematician and daughter of Lord Byron (the English Poet), assisted Babbage’s work and was the first to recognize that the Analytical Engine should not be understood simply as an arithmetical device but rather as a generalized symbol manipulator capable of algebraic and even alphabetical results.  That is, Lovelace correctly recognized Babbage’s invention to be the first universal computing machine (Swade 2001).</p>
  
  <figure style="float:right"><img src="babbage.JPG?key=065fa29196362922a0e92906185966d6c79f7378&type=class&event=12" alt="babbage"><figcaption>Babbage’s Difference Engine <br><a href="../../watch-4.html?v=XSkGY6LchJs">https://www.youtube.com/watch?v=XSkGY6LchJs</a></figcaption></figure>
  
  <p>Nearly a century later, in 1936, another Cambridge mathematician named Alan Turing formally proved that a hypothetical machine (later referred to as a “Turing machine”) using a binary pair of symbols could perform any mathematical computation if it were representable by an algorithm (Turing 1936).  The idea that a machine could perform such rule-based computations, previously only accomplished by humans, was revolutionary and laid the groundwork for modern digital computers.  Turing later utilized this insight in his contributions to the work of WWII-era codebreakers at Bletchley Park, which led to the cracking of the Enigma code utilized by the German military.</p>
  
  <p>Despite the fact that Babbage and Turing both succeeded in producing machines that could replace human cognitive activities, the human element remained essential to the design and implementation of their work.  For Babbage, humans were required to conceive of the machines in the first place, manufacture its parts, write the programs, set up their initial conditions, provide mechanical force for its operation, and interpret the results (Swade 2001).  At each stage errors or malicious actors would be able to thwart its intended outcome.  With physical access to Babbage’s device, a crafty enemy could introduce errant initial settings or even sabotage the physical machine itself—perhaps by grinding away a single cog-tooth thereby undermining the reliability of its results. In the case of the Enigma codebreakers, despite the fact that Enigma settings allowed for over 1.5 x 1019 possible setting permutations, Bletchley analysts were able to break the code because human implementation errors and human-induced cryptographic design weaknesses limited the number of actual permutations to a number solvable by the machine-based decryption techniques available to them (Thimbleby 2016).</p>
  
  <figure style="float:right"><img src="eniac.PNG?key=a45dd612b4443c6d1de35d68825fba7d4947f9fe&type=class&event=12" alt="eniac"><figcaption>Electronic Numerical Integrator and <br>Computer (ENIAC)</figcaption></figure>
  
  <p>By 1946, the University of Pennsylvania had built the Electronic Numerical Integrator and Computer (ENIAC), arguably the first general-purpose electronic computer.  It covered 1,000 square feet and was 10 feet tall.  Programs, once written, took several people to load by setting dials, cable connections, and switches.  Around 50 vacuum tubes per day had to be replaced simply to keep ENIAC running (Grudin 2005).  Through the 1950s, the Soviet Union also made critical advances in computer technology, particularly through their BESM-1, BESM-2, BESM-6, and M-20 computers, which were then the fastest and most powerful computers in Europe (IIS 2015).  Such early computer projects employed people in three critical roles (Grudin 2005): management, programming, and operation.
  <ul>
    <li>Managers oversaw the design, development, and operation of the machine.</li>
    <li>Programmers wrote the programs.</li>
    <li>Operators carried out the tasks required to implement the program.</li>
  </ul>
  Each of these roles was subject to vulnerabilities.  Managers could mismanage, or be caused to do so by malevolent actors seeking to undermine their activities.  Programmers could write unsecure software that introduced vulnerabilities into the system.  Operators could make mistakes or be induced into doing so, thereby affecting the implementation of the program.  As technical sophistication and complexity grew human-related vulnerabilities seemed to grow in tandem.  From the earliest days, humans were essential elements to the functioning and security of computers.
  
  </div>
  
  <div id="phone_phreaking">
  <h2>The 1960s-1980s: Phone Phreaking and the Birth of the Hacker Ethic</h2>
  <p>Early computers weren’t connected to one another, which meant that security concerns largely remained a localized problem.  This changed in the late 1960’s when the Advanced Research Projects Agency Network (ARPANET) was created.  By December 1969, the ARPANET connected computers at the University of California, Los Angeles (UCLA), the University of California, Santa Barbara (UCSB), Stanford University, and the University of Utah.  Six months later computers at the Massachusetts Institute of Technology (MIT), Harvard University, and a small Boston-based firm called Bolt, Beranek and Newman (BBN) were connected (IIS 2015).  As computer networks grew, security concerns relating to lost information, intercepted communications, and the verification of identities began to emerge, albeit among only a small number of specialists (Warner 2012).  Willis H. Ware, an early computer security pioneer, specifically emphasized the importance of humans to security, noting that “[T]here are human vulnerabilities throughout; individual acts can accidentally or deliberately jeopardize the protection of information in a system” (Ware 1967, 11).  Despite such concerns, it was not until the birth of the World Wide Web (WWW) in the 1990s, which marked the beginning of the public commercial internet, that computer security began to emerge as a central concern for anyone but a small minority of specialists.</p>
  
  <p>If computers had not yet been connected to form a network, what had?  In the 1960s-1970s, the most sophisticated networked technology was the telephone system.  Early phone-hackers, calling themselves “<b>phone phreaks</b>” used their growing technical knowledge of the way phone system networks operated—their circuits, switches, relays, tonal complexities, and network diagrams—to hijack the telephone system for their own purposes, whether that be to avoid fees, connect to foreign conference calls, or gain access to areas of the network considered off-limits using normal telephonic protocols (Orth 1971 & Rosenbaum 1971).</p>
  
  <p>One of the early pioneers in phone phreaking, John Draper (aka “Cap’n Crunch”), discovered that a 2600 hertz tone would, when produced by a regular phone user, provide access to the Operator Mode used by phone operators to connect calls to anywhere in the world.  Draper’s nickname “Cap’n Crunch” originated in his discovery that a small toy whistle offered in Cap’n Crunch cereal boxes at the time effectively produced exactly the 2600 Hz necessary to access this Operator Mode (Orth 1971, 28).</p>
  
  <figure style="float:right"><img src="draper.JPG?key=cb9baa501644a475b619ccbba2aa5ca680a8b7e1&type=class&event=12" alt="draper"><figcaption>John “Cap’n Crunch” Draper</figcaption></figure>
  
  <p>Another technique used by phone phreakers utilized what came to be known as a “Blue Box,” a mechanical telephone keypad box—constructed by phreakers themselves—with a speaker allowing tonal output.  By understanding how the telephone calls got routed over network trunk lines, phreakers could trick the network into bypassing the normal toll collection and allow them to route calls on their own (Rosenbaum 1971).</p>
  
  <p>Phone phreakers didn’t confine themselves to technical hacks.  Interviews with John Draper reveal that often he and his friend and fellow pioneer phreaker, Dennis Dan “Denny” Teresi, would use human manipulation techniques called “social engineering” to gain needed information from unsuspecting Bell Telephone employees. Draper described social engineering as “the ability of going in and talking to people on the inside of the phone company…making them believe you were working for the phone company" and acclaimed Teresi as its foremost expert of the day (Draper 2001).  You will learn more about modern social engineering techniques later in the course.</p>
  
  <figure style="float:right"><img src="blue_box.JPG?key=9034cbf410530f47c374c0888d0f0e01e61d2373&type=class&event=12" alt="blue_box"><figcaption>Blue Box</figcaption></figure>
  
  <p>Before phone phreaking, the term “social engineering” had only been applied to the activities of powerful policy planners—individuals in business or government attempting to cure what they identified as “social ills” through the use of their superior technical knowledge of public policy and economics. Phone phreakers inverted this power structure, thereby inaugurating what would later be called the “hacker mentality.” Here were relatively powerless individuals—often teenagers—usurping the designs of powerful phone companies. The other inversion that took place under this new application was from the allegedly benign purposes of the powerful policy planners to the nefarious purposes of the phreakers themselves. Phreakers reversed the social hierarchy that had stood alongside the concept of social engineering and, at the same time, put this tactic to their own disreputable—typically illegal—uses (Hatfield 2018).</p>
  
  <p>Two early phone phreakers, Steve Jobs and Steve “Woz” Wozniak, later founded Apple Computers which helped, in the 1980s, usher in the era of the personal computer (Lee 2001). Throughout that decade, the adoption of the Transmission Control Protocol / Internet Protocol (TCP/IP) model, the invention of the World Wide Web in 1989, the proliferation of personal computers, and the client-server model for network services, effectively united the computer community with the phone phreakers—particularly since early computer networks communicated over telephone lines (Denning and Denning 2016, 5).</p>

  <figure style="float:right"><img src="jobs.JPG?key=b2d202a622faad16de831cd177b77ef8dfddddb6&type=class&event=12" alt="jobs"><figcaption>Steve Jobs, right, with his friend and <br>co-founder, Steve Wozniak</figcaption></figure>
  
  <p>In 1984, the earliest hacker magazine 2600: The Hacker Quarterly, which took its name from the 2600 hertz tone used by phone phreakers, began publishing anonymous articles on how to manipulate and repurpose, or “hack,” technologies such as telephones and the newly available personal computers. Other rival magazines soon appeared such as Phrack (a portmanteau of “phreak” and “hack”) founded by Craig Neidorf (aka "Knight Lightning") alongside Randy Tischler (aka "Taran King"). Phrack began publishing in November 1985 and continues today online (Hatfield 2018). In 1990, Neidorf (alongside Robert Riggs) was later arrested and charged with possession and distribution of a stolen BellSouth document, which BellSouth claimed was worth $80K. Facing up to 31 years in prison, Neidorf’s defense, in United States v. Riggs, was able to demonstrate that the information in the documents could have been acquired for $13 (Denning 1991).</p>
  
  <p>Early phone phreakers and computer hackers shared what scholars call the “hacker ethic,” a sensibility that developed over time and remains prevalent in the hacker underworld.  Principles of the hacker ethic include (Levy 1984, Steinmetz and Gerber 2015):
  <ul>
  <li>Access to computers is a right</li>
  <li>Hackers should be judged by their abilities rather than criteria such as degrees, age, sex/gender, race, or position</li>
  <li>A do-it-yourself mentality of exploration and manipulation</li>
  <li>General disregard for traditional rules and norms</li>
  <li>An assumption that information should be open and available; the burden of proof is on those who want to maintain confidentiality (e.g. governments, corporations)</li>
  <li>The use of anonymity (e.g. nicknames, anonymizing protocols) to protect against unjustified coercion by authorities</li>
  <li>Distrust of authority—promote decentralization</li>
  <li>The sharing of innovations among other like-minded individuals</li>
  </ul>
  The open-source software movement is an extension of this ethic.  So too are the activities of hacker activist (“hacktivist”) groups such as Anonymous, a decentralized international hacktivist group which emerged in 2004 and became widely known for its various Distributed Denial of Service (DDoS) attacks against several governments, government institutions and government agencies, corporations, the Church of Scientology, and other targets (Olson 2013).  Within the World Wide Web that emerged in the 1990s and remains the dominant technology today, such groups have found new ways to carry out rebellion and political activism all while remaining relatively decentralized, anonymous, and free from counterattack—whether by law enforcement or their political enemies.  Such activity raises ethical questions to which we will now turn.
  
  </div>


  <div id="contemporary_ethical_challenges">
  <h2>Contemporary Ethical Challenges</h2>
  
  <p>The term “Cyber Age” today connotes more than just computational devices, but the public use of such devices within a context in which they are connected to each other to form a network. Networked computing brings with it immediate security considerations that stand-alone computational devices, such as Babbage’s Difference Engine, do not. That ethical issues have emerged alongside the growth of computer networks is not surprising.  The cyber domain is inescapably a human domain, and human habits, choices, and behaviors are constrained by both legal and ethical considerations.  That is, legal and ethical considerations impact the way individuals use computers and therefore affects security (Workman 2009). Ethics and law are not the same; a law can be unethical (e.g. slavery in the US prior to the Thirteenth Amendment) and unethical behavior need not be illegal (e.g. a passerby in the street loudly insults someone’s appearance just for fun).  Policy can be partly defined as prudent action in light of these ethical and legal constraints. </p>
  
  <p>One of the most important questions that has arisen in the contemporary ethics of cybersecurity has to do with the role that <b>informed consent</b> plays in the ethical evaluation of a cyber operation.  Hackers are labeled “ethical” or <b>white hat</b> when they are hired by their victims to discover security vulnerabilities and improve the victim’s cybersecurity. In this context, the term “cybersecurity” includes not just the maintenance of the Pillars of Information Assurance within computer networks, but also broader concerns such as physical access to buildings and computer hardware, and virtual (or remote) access via the internet.  In the industry this practice is called <b>penetration-testing</b>. For example, a bank might hire a penetration-testing team to attempt to break into the bank’s network and gain access to sensitive data—perhaps even to notionally steal funds. Once the attempt is made, a report is given to the bank detailing whether and how the team was able to breach the various security barriers along with recommendations aiming to eliminate these vulnerabilities. Because the penetration-test occurs only after consent is given by the victim, the conduct of the breach itself—onsite reconnaissance, physical trespass (e.g. lock picking), dumpster diving, malicious computer-to-computer interaction—is usually understood to be ethical (Hatfield 2019).</p>
    
  <figure style="float:right"><img src="hats.JPG?key=3dd3c016cc3e3dcc5bae4aaa569e0b168a6ac130&type=class&event=12" alt="hats"></figure>
  
  <p>Cybersecurity experts therefore distinguish between “white” and “black” hat hackers using two criteria:
  <ol>
  <li>The purpose of the hacking activity</li>
  <li>Whether prior consent has been granted by the victim</li>
  </ol>
  Penetration-testers (also called “ethical hackers”) are said to wear the white hat because the purpose of their activity is ultimately to improve the security of the company from which they first receive approval before searching for vulnerabilities (Symantec 2018). For this reason Abu-Shaqra Baha and Rocci Luppicini (2016, 64) describe ethical hacking as a “risk-based, cost-effective information security risk assessment strategy.” By contrast, <b>black hat</b> hackers take pains to avoid alerting their victim of their activities which are conducted for malicious purposes, such as the theft of information or money. Sometimes, black hat hackers do make formal approaches to their victims, even pretending to help a victim’s security (as is often the case when a technique called “scareware” is deployed), but this consent cannot be considered <i>informed</i> because crucial information is intentionally withheld from victims in order for such ploys to be effective. For these reasons, black hat hacking is nearly universally considered unethical.  There are also <b>grey hat</b> hackers who fail to gain the consent of their victims before launching their attacks but once a vulnerability is discovered the information is brought to the attention of the victim, sometimes with an expectation that a reward will be given else the hacker may post the vulnerability online for the world to see (Symantec 2018).  Grey hat hacking would still be considered “grey” without the threat of exposure or demand for a reward, since consent was never granted prior to the hacking activity.
  
  <figure style="float:right"><img src="hats_chart.PNG?key=9934ae63ec96d2e4cb6fcc29052b165f66a8be4d&type=class&event=12" alt="hats_chart"></figure>
  
  <p>Consent, therefore, is often understood as a critical component for a cyber operation’s ethical status. Without it, most suppose, even the lightest shade of grey hat hacking—where a noble purpose guided the activity, no threats were employed, and no reward was expected—would remain morally ambiguous. White hat hacking is often thought to be morally unambiguous precisely because it can be characterized by both (1) and (2) above (Hatfield 2019).</p>
  
  <p>Nevertheless, the role of consent as a measure of ethical status can be questioned particularly in cases where acquiring consent would undermine the efficacy of a cyber operation conducted for legitimate ends.  Consider the case of state-sponsored cyber operations where a state or coalition of states deploys cyber capabilities within the context of broader considerations, such as alternative means of persuasion and coercion, intelligence assessments, the prudent use of risk-assessment tools, and both domestic and international legal rules.  In such a context, the victim will typically not provide consent and yet—depending upon the case in question—such cyber operations are not always deemed unethical.  For example, although it has not been confirmed or denied by any government, press reporting indicates that the Stuxnet attack, which may have begun around 2007, was a joint venture by the United States and Israel seeking to sabotage Iran’s nuclear program by infecting Supervisory Control and Data Acquisition (SCADA) systems and Programmable Logic Controllers (PLC) at Iran’s Natanz nuclear facility.  Some analysts concluded that Stuxnet delayed Iran’s program by up to two years (Sanger 2012).  Determining whether this operation was ethical may involve much more than simply considering whether the Iranians had given their consent.  Rather, many people think such a case must be placed within a broader context of international relations, strategic policy, and considerations of just and unjust wars.  The just war tradition, for example, requires that among other factors the use of force must be a last resort, be discriminatory (i.e. no harm to non-combatants), and be proportional to the threat at hand (Smit 2005, Rengger 2010).  Whether Stuxnet qualified as a just action under these conditions continues to be debated.</p>
  
  <figure style="float:right"><img src="questions1.PNG?key=6271d81620fad241b32e71eb41b09e31006df8a1&type=class&event=12" alt="questions1"></figure>
  
  <p>Or consider the case arising in late 2018 when an unknown Russian-speaking grey hat persona going by the nickname “Alexey” started breaking into thousands of MikroTik routers and updating their software to help patch their known vulnerabilities.  By October 2018, Alexey had patched over 100,000 routers, even leaving comments to their owners about the vulnerability and information about how to contact him if desired.  The vulnerability allowed routers to fall prey to “botnet herders” who troll the internet amassing control over thousands of routers for use in DDoS attacks. Alexey told reporters that only 50 people reached out to say “thanks” and the rest were outraged (Cimpanu 2018).  In this case, the purpose of Alexey’s hacks was to improve the security of the targeted routers, and there is no evidence to suggest Alexey had any other motive but to help.  Furthermore, it is probably true that had he sought consent from each router’s owner he would likely have received little interest from wary strangers.  The routers would likely have remained unpatched, thereby increasing the risk of DDoS attacks against innocent victims.  Finally, even if consent had been granted, the process of attaining it would have greatly slowed down Alexey’s otherwise very helpful updates.  Nevertheless, victim outrage in this case seems ethically justified to many.</p>
  
  <figure style="float:right"><img src="questions2.PNG?key=7ed92864179833111f0c3b13be0dfca9fa9b649a&type=class&event=12" alt="questions2"></figure>
  
  <p>Even in white hat hacking, where victim consent is attained, there are confounding ethical questions.  Consider the ethics of white hat social engineering, when human manipulation occurs during penetration-testing.  For example, a bank might hire a penetration-testing team that utilized impersonation techniques to trick employees into letting them into a secure vault (perhaps by posing as an audit team).  Human manipulation raises a host of ethical questions pertaining to both the efficacy of the test and the meaning of informed consent.  For a penetration-test to reflect an accurate assessment of a genuine security posture, victims cannot be told they are being tested.  Such information changes their behavior and may vitiate the accuracy of test results and by extension any future security upgrades that may result.  However, since meaningful consent is usually understood as being a necessary condition for a hacking activity to be considered ethical, withholding consent puts a penetration-test’s ethical status in jeopardy (Hatfield 2019).</p>
  
  <p>Two recent cases illustrate the dangers inherent in human manipulation without consent.  Jacintha Saldanha was a nurse at the same British hospital where Kate Middleton, the Duchess of Cambridge, was admitted. Ms. Saldanha received a phone call from an Australian radio DJ, Malanie Greig, who manipulated her into providing detailed information about the Duchess of Cambridge’s medical condition. Saldanha later committed suicide after the breach went public, even leaving a note blaming the DJ for her death (Sawer 2014). This voice phishing (or vishing) attack involved lying, by means of malicious impersonation, to solicit personal and private information that could be used to benefit the interests of the DJ and her wider audience. In another example, in 2015 a 17-year old autistic British boy named Joseph Edwards hung himself after being manipulated by a ransomware e-mail hoax. The scam claimed that indecent images had been found on the computer and demanded that unless a ransom were paid the images would be reported to the police (Telegraph 2015).</p>
  
  <figure style="float:right"><img src="saldanha.PNG?key=8fdfca049d5782504aa1117e9bd713fd5b8f9c7b&type=class&event=12" alt="saldanha"><figcaption>Jacintha Saldanha</figcaption></figure>
  
  <p>Such tragic cases illustrate how potent human-manipulation can be.  Yet white hat social engineering seems to require that some amount of non-consented human manipulation be allowed if the security of banks and other institutions is to be improved.  How can this occur ethically?</p>
  
  <p>Some scholars have proposed a procedure of post-event informed consent, where data is collected without the victim’s knowledge but not included in the analysis until consent is given (Mack 2014, Pieters et al. 2016). However, this approach simply highlights the fact that there are two potential points of ethical failure, the first when data is being collected and the second when it is being analyzed and disseminated. Philosophically, post-event informed consent therefore reduces to an “ends justify the means” rationale, as if taking nude photos of some unknowing person was excused if that person agreed later to have them published. There are also practical difficulties to this idea. For example, if a significant number of victims fail to give consent the validity of the entire penetration-test is largely undermined. In fact, it will be the most vulnerable employees, those most likely to have practices that result in security violations, who fail to give consent once informed that their behavior had been monitored. Given the fact that often only one phishing e-mail is needed to compromise an entire organization, having only a small number of employees opt-out of the analysis largely nullifies the penetration test’s conclusions (Hatfield 2019).</p>
  
  <figure style="float:right"><img src="edwards.PNG?key=b2b555d7312cc05e45a0ac3fc9f6a28b716becdc&type=class&event=12" alt="edwards"><figcaption>Joseph Edwards (17) committed<br> suicide after being manipulated<br> in a cyber ransom scam</figcaption></figure>
  
  <p>Another strategy is to inform employees during the hiring process that penetration-testing may occur and they must agree to this before being hired.  However, ethicists agree that any consent must be non-coerced; for coerced consent is not consent at all. Such coercion does not have to take explicit and direct forms, but rather may be implicit and indirect. For example, although illegal in the European Union, some companies in the US ask applicants to supply social media login credentials during the hiring process so that they can run a profile check for objectionable content prior to hiring. Many applicants undoubtedly see this as a breach of privacy, but compliance is often attained through the implicit threat that failure to provide credentials would invalidate an applicant’s chances of being hired (Drake 2016). Additionally, individuals without the proper information to know what they are consenting to cannot be said to be providing meaningful consent. Thus, schemes that have employees sign a generic consent to penetration-testing upon being hired (or as a condition of employment) cannot be said to have provided meaningfully informed (and non-coerced) consent to any specific and potentially emotionally-damaging technique employed months or even years afterwards. Such schemes give the legal veneer of informed non-coerced consent but are unable to provide meaningfully-informed consent in an ethical sense. Yet, as noted above, the greater one assures themselves that meaningful consent has been attained the less it seems they can be sure of the validity of their penetration test. This amounts to a dichotomy forcing penetration-testing firms and their customers to choose between the good of their employees (i.e. the victims) and that of the broader firm (Hatfield 2019).</p>
  
  <figure style="float:right"><img src="questions3.PNG?key=fe7a7a480492ee6558b96932a05aa5d74e63fcc0&type=class&event=12" alt="questions3"></figure>
  
  <p>These (and many more) difficult ethical issues have arisen alongside the birth and growth of the cyber domain.  As technology has progressed, so too have the human-related concerns of its developers and users.  As an inescapably human domain, cyberspace was developed in stages, first in the academic laboratory of Charles Babbage, through WWII and the breaking of the Enigma code, and ultimately to the modern internet and World Wide Web.  Hacker sensibility developed alongside this growth, first with the phone phreakers of the 1960s-1970s, through the personal computer revolution of the 1980s, to the modern hacker ethic that informs the activities of individuals, hacktivist groups, and nation-states.</p>
    
  </div>

  <div id="review">
  <h2>Review Questions</h2>
  <p> 1. Describe the general history of computing and the importance of the Difference Machine, Turing Machine, ENIAC, and Apple Computers.<br>
  2. What is social engineering and an example of it? <br>
  3. What are the different kinds of hackers and what kind of cyber operations do they perform? <br>
  4. What are some ethical problems that come from the use of cyberspace? </p>

  </div>
    
    <h2>References</h2>
<p class="MsoNormal" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;line-height:normal'><span style=''>Baha Abu-<span class="SpellE">Shaqra</span>, and <span class="SpellE">Rocci</span> <span class="SpellE">Luppicini</span>. 2016. “<span class="SpellE">Technoethical</span>
Inquiry into Ethical Hacking at a Canadian University.” <i style='mso-bidi-font-style:
normal'>International Journal of <span class="SpellE">Technoethics</span></i>,
Vol. 7, Issue 1: 62-76. <o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span class="SpellE"><span style='line-height:normal;'>Cimpanu</span></span><span style='line-height:normal;'>,
<span class="SpellE">Catalin</span>. 2018. “A mysterious grey-hat is patching
people's outdated <span class="SpellE">MikroTik</span> routers.” ZDNet. <span class="MsoHyperlink"><a href="../../article/a-mysterious-grey-hat-is-patching-peoples-outdated-mikrotik-routers/index.htm">https://www.zdnet.com/article/a-mysterious-grey-hat-is-patching-peoples-outdated-mikrotik-routers/</a></span>
(accessed 27 January 2019).<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span style='line-height:normal;'>Denning,
Dorothy E. 1991. &quot;The United States vs. Craig <span class="SpellE">Neidorf</span>:
A Debate on Electronic Publishing, Constitutional Rights and Hacking,&quot; <i style='mso-bidi-font-style:normal'>Communications of the Association for
Computing Machinery</i>, Vol. 34 (3): 22-43.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span style='line-height:normal;'>Denning,
Peter J., and Dorothy E. Denning. 2016. &quot;Cybersecurity is <span class="GramE">Harder</span> than Building Bridges.&quot; <i style='mso-bidi-font-style:
normal'>American Scientist</i> 104(3): 1-6.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;margin-bottom:.0001pt;text-indent:-.25in;line-height:normal'><span style=''>Drake, John R.
2016. “Asking for Facebook Logins: An Egoist Case for Privacy.” <i style='mso-bidi-font-style:normal'>Journal of Business Ethics</i>, Vol. 139:
429-441.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span style='line-height:normal;'>Draper,
John. 2001. <i style='mso-bidi-font-style:normal'>The Secret History of
Hacking. </i>Documentary Film. Directed by Ralph Lee. London: 3BM Television.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span style=';color:black'>Greiner, Lynn. 2008.
“Hacking your network’s weakest link – you.” <i style='mso-bidi-font-style:
normal'>Network Magazine</i> 12(1):9–<span style='mso-bidi-font-weight:bold'>12.<o:p></o:p></span></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span class="SpellE"><span style='mso-bidi-font-size:11.0pt;;
color:black;mso-bidi-font-weight:bold'>Grudin</span></span><span style='mso-bidi-font-size:11.0pt;;
color:black;mso-bidi-font-weight:bold'>, Jonathan. 2005. “Three Faces of
Human-Computer Interaction.” <i style='mso-bidi-font-style:normal'>IEEE Annals
of the History of Computing</i> 27(4): 46-62.</span><span style='font-size:
14.0pt;mso-bidi-;
color:black;mso-bidi-font-weight:bold'><o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span style=';color:black;mso-bidi-font-weight:
bold'>Hatfield, Joseph. 2018. “Social Engineering in Cybersecurity: The
Evolution of a Concept.” <i style='mso-bidi-font-style:normal'>Computers &amp;
Security</i>, Vol. 73, pp. 102-113.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span style=';color:black;mso-bidi-font-weight:
bold'><span style='font-family:"Times New Roman"'>———</span>. 2019. “Virtuous Human Hacking: The Ethics of Social Engineering in
Penetration-Testing.” <i style='mso-bidi-font-style:normal'>Computers &amp;
Security</i> Vol. 83, pp. 354-366.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span style=';color:black;mso-bidi-font-weight:
bold'>IIS, International Institute for Strategic Studies. 2015. <i style='mso-bidi-font-style:normal'>Evolution of the Cyber Domain: The
Implications for National and Global Security</i>. New York: Routledge.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span style='line-height:normal;'>Lee,
Ralph. 2001. <i style='mso-bidi-font-style:normal'>The Secret History of
Hacking. </i>Documentary Film. Directed by Ralph Lee. London: 3BM Television.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span style='line-height:normal;'>Levy,
Stephen. 1984. <i style='mso-bidi-font-style:normal'>Hackers: Heroes of the
Computer Revolution</i>. New York: Doubleday.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;line-height:normal'><span style=';mso-bidi-font-weight:
bold'>Mack, S. 2014. <i style='mso-bidi-font-style:normal'>Reasoning and Judgements
Made in an Online Capacity: An Exploration of how Phishing Emails Influence
Decision Making Strategies</i> (Unpublished dissertation). Lancaster
University, Lancaster, UK.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span style='line-height:normal;'>Olson,
<span class="SpellE">Parmy</span>. 2013. <i style='mso-bidi-font-style:normal'>We
Are Anonymous: Inside the Hacker World of <span class="SpellE">LulzSec</span>,
Anonymous, and the Global Cyber Insurgency</i>. New York: Little, Brown and
Company.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span style='line-height:normal;'>Orth,
Maureen. 1971. &quot;For Whom Ma Bell Tolls Not.&quot; <i style='mso-bidi-font-style:
normal'>Los Angeles Times</i>, Oct. 31 (1971), pp. 28-32.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span style=';color:black;mso-bidi-font-weight:
bold'>Peters, Bernard. 1967. “Security Considerations in a Multi-programmed
Computer System.” <i style='mso-bidi-font-style:normal'>Spring Joint Computer
Conference, AFIPS Proc</i>., <span class="GramE">Vol</span>. 30, pp. 283–286.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span class="SpellE"><span style='line-height:normal;'>Pieters</span></span><span style='line-height:normal;'>,
<span class="SpellE">Wolter</span>, Dina <span class="SpellE">Hadžiosmanovi&#263;</span>,
and <span class="SpellE">Francien</span> <span class="SpellE">Dechesne</span>. 2016.
“Security-by-Experiment: Lessons from Responsible Deployment in Cyberspace.” <i style='mso-bidi-font-style:normal'>Science and Engineering Ethics</i>, Vol. 22:
831-850.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span class="SpellE"><span style='line-height:normal;'>Rengger</span></span><span style='line-height:normal;'>,
Nicholas. 2010. “The Ethics of War: The Just War Tradition.” In <i style='mso-bidi-font-style:normal'>Ethics and World Politics</i>, edited by
Duncan Bell, 292-308. Oxford: Oxford University Press.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-left:.25in;text-indent:-.25in;margin-bottom:6.0pt'><span style='line-height:normal;'>Rosenbaum,
Ron. 1971. &quot;Secrets of the Little Blue Box.&quot; <i style='mso-bidi-font-style:
normal'>Esquire Magazine</i>, Oct. (1971), pp. 117-125, 222-226.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in'><span style=';
color:black;mso-bidi-font-weight:bold'>Sanger, David. 2012. “Obama</span> <span style=';color:black;mso-bidi-font-weight:
bold'>Order Sped Up Wave of Cyberattacks Against Iran.” <i style='mso-bidi-font-style:
normal'>New York Times</i>:<span style='mso-spacerun:yes'>  </span></span><span class="MsoHyperlink"><span style=';mso-bidi-font-weight:
bold'><a href="../../2012/06/01/world/middleeast/obama-ordered-wave-of-cyberattacks-against-iran-1.html?pagewanted=2&amp;_r=1&amp;seid=auto&amp;smid=tw-nytimespolitics&amp;pagewanted=all">https://www.nytimes.com/2012/06/01/world/middleeast/obama-ordered-wave-of-cyberattacks-against-iran.html?pagewanted=2&amp;_r=1&amp;seid=auto&amp;smid=tw-nytimespolitics&amp;pagewanted=all</a></span></span><span style=';color:black;mso-bidi-font-weight:
bold'> (accessed 27 January 2019).<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in'><span class="SpellE"><span style=';mso-bidi-font-weight:bold'>Sawer</span></span><span style=';mso-bidi-font-weight:bold'>,
Patrick. 2014. “Tearful DJ <span class="SpellE">apologises</span> for prank call
which led to nurse's suicide.” <i style='mso-bidi-font-style:normal'>The
Telegraph</i>, URL: <span class="MsoHyperlink"><a href="../../news/uknews/kate-middleton/11092497/Tearful-DJ-apologises-for-prank-call-which-led-to-nurses-suicide.html">https://www.telegraph.co.uk/news/uknews/kate-middleton/11092497/Tearful-DJ-apologises-for-prank-call-which-led-to-nurses-suicide.html</a></span><span style='color:black'><o:p></o:p></span></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in'><span style=';
color:black;mso-bidi-font-weight:bold'>Smit, W. 2005. <i style='mso-bidi-font-style:
normal'>Just War and Terrorism: The End of the Just War Concept?</i> Dudley:
Peters Publishing.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in'><span style=';
color:black;mso-bidi-font-weight:bold'>Steinmetz, Kevin, and <span class="SpellE">Jurg</span> Gerber. 2015. “‘It Doesn’t Have to be This Way’:
Hacker Perspectives on Privacy.” <i style='mso-bidi-font-style:normal'>Social
Justice</i> 41(3): p. 29.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;line-height:normal'><span class="SpellE"><span style='mso-bidi-font-size:11.0pt;;
mso-bidi-font-family:"Times New Roman";mso-bidi-theme-font:minor-bidi;
color:black;mso-bidi-font-weight:bold'>Swade</span></span><span style='mso-bidi-font-size:11.0pt;;
mso-bidi-font-family:"Times New Roman";mso-bidi-theme-font:minor-bidi;
color:black;mso-bidi-font-weight:bold'>, <span class="SpellE">Doron</span>. 2001.
<i style='mso-bidi-font-style:normal'>The Difference Engine: Charles Babbage
and the Quest to Build the First Computer.</i> New York: Viking-Penguin</span><span style=';mso-bidi-font-family:"Times New Roman";
mso-bidi-theme-font:minor-bidi;color:black;mso-bidi-font-weight:bold'>.</span><span style=''> <o:p></o:p></span></p>

<p class="MsoNormal" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;line-height:normal'><span style=''>Symantec. 2018.
“What is the Difference between White, Black and Grey Hat Hackers?” URL: <span class="MsoHyperlink"><a href="../../internetsecurity-emerging-threats-what-is-the-difference-between-black-white-and-grey-hat-hackers.html">https://us.norton.com/internetsecurity-emerging-threats-what-is-the-difference-between-black-white-and-grey-hat-hackers.html</a></span>,
Accessed August 7, 2018.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;line-height:normal'><span style=''>Telegraph. 2015.
“Autistic boy hanged himself after receiving bogus 'police' email.” <i style='mso-bidi-font-style:normal'>The Telegraph</i>, URL = <span class="MsoHyperlink"><a href="../../news/uknews/11363099/Autistic-boy-hanged-himself-after-receiving-bogus-police-email.html">https://www.telegraph.co.uk/news/uknews/11363099/Autistic-boy-hanged-himself-after-receiving-bogus-police-email.html</a></span><o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span class="SpellE"><span style=';color:black;
mso-bidi-font-weight:bold'>Thimbleby</span></span><span style='color:black;mso-bidi-font-weight:bold'>, Harold. 2016.
“Human Factors and Missed Solutions to Enigma Design Weaknesses.” <span class="SpellE"><i style='mso-bidi-font-style:normal'>Cryptologia</i></span>
40(2): 177-202.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span style=';color:black;mso-bidi-font-weight:
bold'>Turing, Alan. 1936. &quot;On Computable Numbers, with an Application to
the <span class="SpellE"><i>Entscheidungs</i></span> (Decision)
problem.&quot;&nbsp;<i>Proceedings of the London Mathematical Society</i>, Vol.
s2-42, Issue 1: pp. 230-265.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span style=';color:black;mso-bidi-font-weight:
bold'><span style='font-family:"Times New Roman"'>———</span>. 2001. “Mathematical Logic.” <i style='mso-bidi-font-style:normal'>Collected
Works of Alan Turing</i>, Vo. 4. Edited by R.O. Gandy and C.E.M Yates,
Amsterdam: Elsevier Science.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span style=';color:black;mso-bidi-font-weight:
bold'>Ware, Willis H. 1967. “Security and Privacy in Computer Systems.” <i style='mso-bidi-font-style:normal'>Spring Joint Computer Conference, AFIPS Proc</i>.,
<span class="GramE">Vol</span>. 30, pp. 1-28.<o:p></o:p></span></p>

<p class="Style0" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:-.25in;tab-stops:.5in 1.0in 1.5in 2.0in 2.5in 3.0in 3.5in 4.0in 4.5in 5.0in 5.5in 6.0in'><span style=';color:black;mso-bidi-font-weight:
bold'>Warner, Michael. 2012. “Cybersecurity: A Pre-History.” <i style='mso-bidi-font-style:normal'>Intelligence and National Security</i> 27(5),
781-799.<o:p></o:p></span></p>

<p class="MsoNormal" style='margin-top:0in;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;margin-bottom:.0001pt;text-indent:-.25in;line-height:normal'><span style=';mso-bidi-font-weight:
bold'>Workman, Michael. 2009. “How Perceptions of Justice Affect Security
Attitudes: Suggestions for Practitioners and Researchers.” <i style='mso-bidi-font-style:
normal'>Information Management &amp; Computer Security</i> 17(4): 1341-353.</span><span style=''><o:p></o:p></span></p>
  </div>
  </body>
  </html></div> <!-- /container --></body></html>